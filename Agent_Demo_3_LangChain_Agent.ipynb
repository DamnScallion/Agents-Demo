{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DamnScallion/Agents-Demo/blob/main/Agent_Demo_3_LangChain_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334",
      "metadata": {
        "id": "39fd1948-b5c3-48c4-b10e-2ae7e8c83334"
      },
      "source": [
        "# LangChain Agent Demo\n",
        "\n",
        "This is a LangChain Agent Demo\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, let's install our required packages and set our API keys:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d7b6dcc-c985-46e2-8457-7e6b0298b950",
      "metadata": {
        "id": "0d7b6dcc-c985-46e2-8457-7e6b0298b950",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f81c61a-6d3c-4167-a608-0d3e66be6924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.0/662.0 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install packages\n",
        "!pip install langchain openai tiktoken langchain-community chromadb pypdf -U -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup OpenAI API Key"
      ],
      "metadata": {
        "id": "AzosUwZ0md9H"
      },
      "id": "AzosUwZ0md9H"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up OpenAI API Key (REPLACE with your own key)\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"REPLACE THIS STRING WITH YOUR OPEN API KEY\""
      ],
      "metadata": {
        "id": "0YfsLte2mjC0"
      },
      "id": "0YfsLte2mjC0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import LangChain libraries/modules"
      ],
      "metadata": {
        "id": "gUxkl-x9mqih"
      },
      "id": "gUxkl-x9mqih"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import standard LangChain modules\n",
        "from langchain.agents import initialize_agent, Tool, AgentType, load_tools\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain, LLMMathChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langchain.embeddings import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "eUbZMSS9mX0G"
      },
      "id": "eUbZMSS9mX0G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA, create_retrieval_chain\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_community.embeddings.sentence_transformer import (\n",
        "    SentenceTransformerEmbeddings,\n",
        ")"
      ],
      "metadata": {
        "id": "pofLy6zEy0pi"
      },
      "id": "pofLy6zEy0pi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize OpenAI LLM"
      ],
      "metadata": {
        "id": "9vqAHrGQmxqK"
      },
      "id": "9vqAHrGQmxqK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OpenAI LLM\n",
        "llm = OpenAI(temperature=0.0001)"
      ],
      "metadata": {
        "id": "uRvv6wsjmw9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e03a61d5-c894-482e-907d-b2b384ef6424"
      },
      "id": "uRvv6wsjmw9w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-d6eb68d2ddb7>:2: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = OpenAI(temperature=0.0001)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Langchain.agents all the tool names"
      ],
      "metadata": {
        "id": "8odW0K8jnNg0"
      },
      "id": "8odW0K8jnNg0"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import get_all_tool_names\n",
        "get_all_tool_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTmXKL5KnJue",
        "outputId": "d119d3d1-624a-493e-a947-70c98a40b7bf"
      },
      "id": "dTmXKL5KnJue",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sleep',\n",
              " 'wolfram-alpha',\n",
              " 'google-search',\n",
              " 'google-search-results-json',\n",
              " 'searx-search-results-json',\n",
              " 'bing-search',\n",
              " 'metaphor-search',\n",
              " 'ddg-search',\n",
              " 'google-books',\n",
              " 'google-lens',\n",
              " 'google-serper',\n",
              " 'google-scholar',\n",
              " 'google-finance',\n",
              " 'google-trends',\n",
              " 'google-jobs',\n",
              " 'google-serper-results-json',\n",
              " 'searchapi',\n",
              " 'searchapi-results-json',\n",
              " 'serpapi',\n",
              " 'dalle-image-generator',\n",
              " 'twilio',\n",
              " 'searx-search',\n",
              " 'merriam-webster',\n",
              " 'wikipedia',\n",
              " 'arxiv',\n",
              " 'golden-query',\n",
              " 'pubmed',\n",
              " 'human',\n",
              " 'awslambda',\n",
              " 'stackexchange',\n",
              " 'sceneXplain',\n",
              " 'graphql',\n",
              " 'openweathermap-api',\n",
              " 'dataforseo-api-search',\n",
              " 'dataforseo-api-search-json',\n",
              " 'eleven_labs_text2speech',\n",
              " 'google_cloud_texttospeech',\n",
              " 'read_file',\n",
              " 'reddit_search',\n",
              " 'news-api',\n",
              " 'tmdb-api',\n",
              " 'podcast-api',\n",
              " 'memorize',\n",
              " 'llm-math',\n",
              " 'open-meteo-api',\n",
              " 'requests',\n",
              " 'requests_get',\n",
              " 'requests_post',\n",
              " 'requests_patch',\n",
              " 'requests_put',\n",
              " 'requests_delete',\n",
              " 'terminal']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agents\n",
        "- Zero-shot-agent (Zero-shot-agent could not remember memories)\n",
        "- ReAct Conversational Agent (Conversational Agent allows dialogue and remmber previous chat history)\n",
        "\n",
        "### Tool\n",
        "- Math Tool\n",
        "- Language Tool\n",
        "- Retriever Tool"
      ],
      "metadata": {
        "id": "U1uaV0kynXmo"
      },
      "id": "U1uaV0kynXmo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1: Math Tool Agent (Zero-shot)"
      ],
      "metadata": {
        "id": "tek08Uonny31"
      },
      "id": "tek08Uonny31"
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Math Tool Agent (Zero-shot)\n",
        "tools = load_tools([\"llm-math\"], llm=llm)\n",
        "math_agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ],
      "metadata": {
        "id": "NmpO4Wzxm2ie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebf5dd6-0a12-4f2b-d1f4-415b33c6ef1a"
      },
      "id": "NmpO4Wzxm2ie",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-f6af386e05f2>:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  math_agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the agent\n",
        "math_agent.run(\"What is (4.5 * 2.1)^2.2?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "Y2Nmv2yCntL0",
        "outputId": "18bee530-b135-4086-863f-75a48507de32"
      },
      "id": "Y2Nmv2yCntL0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-2505134ab57a>:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  math_agent.run(\"What is (4.5 * 2.1)^2.2?\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use a calculator to solve this problem.\n",
            "Action: Calculator\n",
            "Action Input: (4.5 * 2.1)^2.2\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 139.94261298333066\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: 139.94261298333066\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'139.94261298333066'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2: Language Tool"
      ],
      "metadata": {
        "id": "F9afhtrAoZfS"
      },
      "id": "F9afhtrAoZfS"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "wYwxjfAdoAgI"
      },
      "id": "wYwxjfAdoAgI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple LLM chain using a prompt\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"query\"],\n",
        "    template=\"{query}\"\n",
        ")"
      ],
      "metadata": {
        "id": "PksMZ8O_ojYD"
      },
      "id": "PksMZ8O_ojYD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "LV8QbRcqoowx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d82c11-477e-47c6-9e3b-b80db328cbe3"
      },
      "id": "LV8QbRcqoowx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-8a5533dae036>:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  llm_chain = LLMChain(llm=llm, prompt=prompt)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_tool = Tool(\n",
        "    name=\"Language Model\",\n",
        "    func=llm_chain.run,\n",
        "    description=\"General purpose LLM queries\"\n",
        ")\n",
        "\n",
        "tools.append(llm_tool)"
      ],
      "metadata": {
        "id": "uRI8jaCkouAP"
      },
      "id": "uRI8jaCkouAP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2: Zero-shot Agent"
      ],
      "metadata": {
        "id": "p7_FshD4o__j"
      },
      "id": "p7_FshD4o__j"
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_agent = initialize_agent(\n",
        "    agent = \"zero-shot-react-description\",\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    verbose = True,\n",
        "    max_iterations = 3\n",
        ")"
      ],
      "metadata": {
        "id": "0T9PKzdVo0Dj"
      },
      "id": "0T9PKzdVo0Dj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_agent(\"What is the capital of Australia? What is the number of population of this capital divided by 2?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJNL9uR0o-0D",
        "outputId": "fc7b6426-3f08-481f-8b86-9ff4b6332769"
      },
      "id": "yJNL9uR0o-0D",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-af78a97c0d3f>:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  zero_shot_agent(\"What is the capital of Australia? What is the number of population of this capital divided by 2?\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m We can use a language model to find the capital of Australia and then use a calculator to divide the population by 2.\n",
            "Action: Language Model\n",
            "Action Input: \"What is the capital of Australia?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "\n",
            "The capital of Australia is Canberra.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Now we can use a calculator to divide the population by 2.\n",
            "Action: Calculator\n",
            "Action Input: 410000\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 410000\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: The population of Canberra divided by 2 is 205000.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is the capital of Australia? What is the number of population of this capital divided by 2?',\n",
              " 'output': 'The population of Canberra divided by 2 is 205000.'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 3: ReAct Agent\n",
        "\n",
        "- conversational-react-description agent\n",
        "- Benifit: have memory can memory the previous chat history"
      ],
      "metadata": {
        "id": "BO7Ct-WDpjzY"
      },
      "id": "BO7Ct-WDpjzY"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
      ],
      "metadata": {
        "id": "yk0HpIAfpx7a"
      },
      "id": "yk0HpIAfpx7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        "    max_iterations=3\n",
        ")"
      ],
      "metadata": {
        "id": "M4gkgEqppLvI"
      },
      "id": "M4gkgEqppLvI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = conversational_agent.run({\"input\": \"What are the GDP of Australia over the past 5 years? Then divide it by the GDP of Germany?\", \"chat_history\":[]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eqLzo7Pr0GP",
        "outputId": "a13b6820-b48f-4602-ac66-003ead1881c1"
      },
      "id": "2eqLzo7Pr0GP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Language Model\n",
            "Action Input: The GDP of Australia over the past 5 years divided by the GDP of Germany\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m over the past 5 years\n",
            "\n",
            "The GDP of Australia over the past 5 years: \n",
            "2016: $1.2 trillion\n",
            "2017: $1.3 trillion\n",
            "2018: $1.4 trillion\n",
            "2019: $1.4 trillion\n",
            "2020: $1.4 trillion\n",
            "\n",
            "Total GDP over 5 years: $6.7 trillion\n",
            "\n",
            "The GDP of Germany over the past 5 years:\n",
            "2016: $3.5 trillion\n",
            "2017: $3.7 trillion\n",
            "2018: $3.9 trillion\n",
            "2019: $3.9 trillion\n",
            "2020: $3.8 trillion\n",
            "\n",
            "Total GDP over 5 years: $18.8 trillion\n",
            "\n",
            "The ratio of Australia's GDP to Germany's GDP over the past 5 years is:\n",
            "$6.7 trillion / $18.8 trillion = 0.356\n",
            "\n",
            "Therefore, the GDP of Australia over the past 5 years is approximately 35.6% of the GDP of Germany over the past 5 years.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: The ratio of Australia's GDP to Germany's GDP over the past 5 years is approximately 35.6%. Is there anything else I can assist you with?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = conversational_agent.run(\"What would be the result if the above result add the GDP of France?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnKEtvhYt3a4",
        "outputId": "557fa386-f3fa-4c7a-dffd-c7cdb964e608"
      },
      "id": "UnKEtvhYt3a4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAI: The result would be the total GDP of the four countries (Spain, France, Portugal, and France) combined. Is there anything else I can assist you with?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 4: Agentic RAG\n",
        "\n",
        "Agentic Retrieval-Augmented Generation (Agentic RAG) is an emerging AI paradigm where large language models (LLMs) autonomously plan their next steps while pulling information from external sources. Unlike static retrieval-then-read patterns, Agentic RAG involves iterative calls to the LLM, interspersed with tool or function calls and structured outputs. The system evaluates results, refines queries, invokes additional tools if needed, and continues this cycle until a satisfactory solution is achieved."
      ],
      "metadata": {
        "id": "-0iuajPPwFsE"
      },
      "id": "-0iuajPPwFsE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load source documents"
      ],
      "metadata": {
        "id": "FnWhgGBozGzk"
      },
      "id": "FnWhgGBozGzk"
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader('./', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
        "\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JW5Bi0HzCCx",
        "outputId": "a05ab9ac-3230-4047-b96c-b2379575d91c"
      },
      "id": "1JW5Bi0HzCCx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 11 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 34 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 48 0 (offset 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create RAG knowledge base"
      ],
      "metadata": {
        "id": "SF1OewDE1GrU"
      },
      "id": "SF1OewDE1GrU"
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
        "embedding = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=texts,\n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=\"db\")\n",
        "\n",
        "vectordb.persist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT_ET963zNvc",
        "outputId": "698e4740-f9f8-4ac7-b437-2fe5cbb5d74a"
      },
      "id": "XT_ET963zNvc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-74-9b140d77dfaa>:8: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectordb.persist()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "wO2w9jovwFBb"
      },
      "id": "wO2w9jovwFBb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create RAG Retriever Tool"
      ],
      "metadata": {
        "id": "QRsKT3jpzuP9"
      },
      "id": "QRsKT3jpzuP9"
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"RAG_search\",\n",
        "    \"Search for information about Strata domain knowledge. For any questions about Strata Inspection Report, you must use this tool\"\n",
        ")"
      ],
      "metadata": {
        "id": "0q-iUQCqx2ma"
      },
      "id": "0q-iUQCqx2ma",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools.append(retriever_tool)"
      ],
      "metadata": {
        "id": "ZIeUOi-4yJTf"
      },
      "id": "ZIeUOi-4yJTf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_agent = initialize_agent(\n",
        "    agent = 'conversational-react-description',\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    verbose = True,\n",
        "    memory = memory,\n",
        "    max_iterations = 3\n",
        ")"
      ],
      "metadata": {
        "id": "66s9AslUyMow"
      },
      "id": "66s9AslUyMow",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = conversational_agent.run(\"What is Motion 10, Open Discussion in the strata inspection report? Use tools if needed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv_dxk_j166N",
        "outputId": "09f9be2a-f6a6-4aa3-ff2d-701de081f888"
      },
      "id": "Kv_dxk_j166N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: RAG_search\n",
            "Action Input: Motion 10, Open Discussion\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m Motion 9: EV charging station \n",
            "That the Strata Committee revisit the possibility for the installation of EV charging infrastructure \n",
            "on either common property or authority for lot owners to install EV charging infrastructure \n",
            "within their car space (on specific conditions). \n",
            " \n",
            "That the strata manager is to investigate the cost of installation of EV chargers and provide an \n",
            "update to the committee. \n",
            " Motion 10: Open Discussion\n",
            "\n",
            "Motion is to be reviewed at next committee meeting. \n",
            " Motion 9: Fire panel malfunction \n",
            "That the fire safety panel has malfunction causing several false alarms within a short period of \n",
            "time. Strata committee to review the situation and determine appropriate course of action and \n",
            "process. \n",
            " \n",
            "That the building manager confirms the panel has been repaired. \n",
            " \n",
            "The fire panel malfunction results in false alarm going off causing residents to evacuate due to\n",
            "\n",
            "adjacent development and the installation of a pedestrian crossing. \n",
            " \n",
            "13TH May 2024 SCM: (Minutes Attached)   \n",
            " Motion 5: Gardening/Irrigation \n",
            "That the building manager provide an update in relation to the current status of the garden and \n",
            "irrigation system. \n",
            " \n",
            "That the building manager is to contact council and propose that they install rubbish bins on \n",
            "the pedestrian pathway at entry points to the estate thoroughfare between buildings A and B. \n",
            " Motion 8: Building Defects\n",
            "\n",
            "April 2023 in full and final settlement of the Defects Litigation. \n",
            "16th March 2023 EGM: (Minutes Attached)   \n",
            " Motion 2: Defects Litigation \n",
            "It was resolved that the Owners Corporation was in favour of rejecting the Builder’s settlement \n",
            "offer dated 10 February 2023. \n",
            " Motion 3: Defects Litigation \n",
            "The Owners Corporation resolves for MC Lawyers & Advisers (with the assistance of experts as \n",
            "necessary) to formulate and send settlement offers to the Defendants in the Defects Litigation\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: Motion 10 in a strata inspection report refers to a proposal for an open discussion among the owners corporation about a specific topic or issue related to the building. This could include things like maintenance concerns, proposed renovations, or changes to bylaws. Is there anything else I can assist you with?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = conversational_agent(\"What is Motion 9, EV charging station in the strata inspection report? Use Tool if needed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrL2K0gyyUTb",
        "outputId": "f52d51b0-107c-4695-cebd-3e3055c413b7"
      },
      "id": "CrL2K0gyyUTb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: RAG_search\n",
            "Action Input: Motion 9, EV charging station\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m Motion 9: EV charging station \n",
            "That the Strata Committee revisit the possibility for the installation of EV charging infrastructure \n",
            "on either common property or authority for lot owners to install EV charging infrastructure \n",
            "within their car space (on specific conditions). \n",
            " \n",
            "That the strata manager is to investigate the cost of installation of EV chargers and provide an \n",
            "update to the committee. \n",
            " Motion 10: Open Discussion\n",
            "\n",
            "Strata Inspection Report:  SP 93491 Lot 208 \n",
            " \n",
            "    \n",
            "Nick Lazaris   |   0404 295 839   |   hello@yourstratasolutions.com.au 8 \n",
            " \n",
            "Meriton informs that defects rectification is delayed due to constant wet weather, however they \n",
            "are still working to complete all defects as per agreement with the Owners Corporation. \n",
            " Motion 9: EV charging station \n",
            "That the Strata Committee revisit the possibility for the installation of EV charging infrastructure\n",
            "\n",
            "That the strata manager is to investigate the cost of installation of EV chargers and provide an \n",
            "update to the committee. \n",
            " Motion 10: Open Discussion \n",
            "That the committee review and discussion any further issues relevant to the strata scheme. \n",
            "Action items: \n",
            " \n",
            "That the strata manager is to provide a graph showing cashflow for the strata plan trust account \n",
            "in monthly intervals to the committee. Based on a review of the cashflow the committee will\n",
            "\n",
            "Motion is to be reviewed at next committee meeting. \n",
            " Motion 9: Fire panel malfunction \n",
            "That the fire safety panel has malfunction causing several false alarms within a short period of \n",
            "time. Strata committee to review the situation and determine appropriate course of action and \n",
            "process. \n",
            " \n",
            "That the building manager confirms the panel has been repaired. \n",
            " \n",
            "The fire panel malfunction results in false alarm going off causing residents to evacuate due to\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: Motion 9 in a strata inspection report refers to a proposal to install an EV charging station in the building's parking lot. This motion may have been brought up by a member of the strata committee or by a resident, and it would need to be voted on by the owners corporation before any action can be taken. Is there anything else I can assist you with?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}